"""add_normalized_documents_table

Revision ID: 114ec95d9e6a
Revises: b984555eaae5
Create Date: 2025-08-22 09:25:54.740638

"""

from collections.abc import Sequence

import sqlalchemy as sa
from alembic import op
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = "114ec95d9e6a"
down_revision: str | None = "b984555eaae5"
branch_labels: str | Sequence[str] | None = None
depends_on: str | Sequence[str] | None = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table(
        "documents",
        sa.Column("uid", sa.String(length=255), nullable=False),
        sa.Column("source", sa.String(length=50), nullable=False),
        sa.Column("source_id", sa.String(length=100), nullable=False),
        sa.Column("title", sa.Text(), nullable=True),
        sa.Column("published_at", sa.DateTime(timezone=True), nullable=True),
        sa.Column("s3_raw_uri", sa.Text(), nullable=False),
        sa.Column("content_hash", sa.String(length=64), nullable=False),
        sa.Column("created_at", sa.DateTime(timezone=True), nullable=False),
        sa.PrimaryKeyConstraint("uid"),
    )
    op.create_index(
        op.f("ix_documents_published_at"), "documents", ["published_at"], unique=False
    )
    op.create_index(op.f("ix_documents_source"), "documents", ["source"], unique=False)
    op.create_table(
        "documents_universal",
        sa.Column("id", sa.String(length=255), nullable=False),
        sa.Column("source", sa.String(length=50), nullable=False),
        sa.Column("source_id", sa.String(length=100), nullable=False),
        sa.Column("title", sa.Text(), nullable=False),
        sa.Column("abstract", sa.Text(), nullable=True),
        sa.Column("content", sa.Text(), nullable=True),
        sa.Column("authors", sa.JSON(), nullable=True),
        sa.Column("publication_date", sa.DateTime(), nullable=True),
        sa.Column("source_metadata", sa.JSON(), nullable=True),
        sa.Column("quality_score", sa.Integer(), nullable=True),
        sa.Column("last_updated", sa.DateTime(), nullable=True),
        sa.Column("created_at", sa.DateTime(), nullable=False),
        sa.Column("updated_at", sa.DateTime(), nullable=False),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index(
        op.f("ix_documents_universal_last_updated"),
        "documents_universal",
        ["last_updated"],
        unique=False,
    )
    op.create_index(
        op.f("ix_documents_universal_publication_date"),
        "documents_universal",
        ["publication_date"],
        unique=False,
    )
    op.create_index(
        op.f("ix_documents_universal_quality_score"),
        "documents_universal",
        ["quality_score"],
        unique=False,
    )
    op.create_index(
        op.f("ix_documents_universal_source"),
        "documents_universal",
        ["source"],
        unique=False,
    )
    op.drop_table("pubmed_documents")
    op.alter_column(
        "corpus_checkpoints",
        "version",
        existing_type=sa.VARCHAR(length=50),
        nullable=True,
        existing_server_default=sa.text("'1.0'::character varying"),
    )
    op.alter_column(
        "corpus_checkpoints",
        "document_count",
        existing_type=sa.VARCHAR(length=20),
        type_=sa.String(length=50),
        nullable=True,
        existing_server_default=sa.text("'0'::character varying"),
    )
    op.alter_column(
        "corpus_checkpoints",
        "last_sync_edat",
        existing_type=sa.VARCHAR(length=10),
        type_=sa.String(length=50),
        existing_nullable=True,
    )
    op.alter_column(
        "corpus_checkpoints",
        "total_documents",
        existing_type=sa.VARCHAR(length=20),
        type_=sa.String(length=50),
        nullable=True,
        existing_server_default=sa.text("'0'::character varying"),
    )
    op.alter_column(
        "corpus_checkpoints",
        "total_vectors",
        existing_type=sa.VARCHAR(length=20),
        type_=sa.String(length=50),
        nullable=True,
        existing_server_default=sa.text("'0'::character varying"),
    )
    op.alter_column(
        "corpus_checkpoints",
        "created_at",
        existing_type=postgresql.TIMESTAMP(timezone=True),
        type_=sa.DateTime(),
        existing_nullable=False,
        existing_server_default=sa.text("now()"),
    )
    op.alter_column(
        "corpus_checkpoints",
        "updated_at",
        existing_type=postgresql.TIMESTAMP(timezone=True),
        type_=sa.DateTime(),
        existing_nullable=False,
        existing_server_default=sa.text("now()"),
    )
    op.drop_column("corpus_checkpoints", "sync_watermarks")
    op.add_column(
        "sync_watermarks",
        sa.Column("id", sa.Integer(), autoincrement=True, nullable=False),
    )
    op.add_column(
        "sync_watermarks", sa.Column("source", sa.String(length=50), nullable=False)
    )
    op.add_column(
        "sync_watermarks", sa.Column("last_sync", sa.DateTime(), nullable=False)
    )
    op.alter_column(
        "sync_watermarks",
        "created_at",
        existing_type=postgresql.TIMESTAMP(timezone=True),
        type_=sa.DateTime(),
        existing_nullable=False,
        existing_server_default=sa.text("now()"),
    )
    op.alter_column(
        "sync_watermarks",
        "updated_at",
        existing_type=postgresql.TIMESTAMP(timezone=True),
        type_=sa.DateTime(),
        existing_nullable=False,
        existing_server_default=sa.text("now()"),
    )
    op.drop_column("sync_watermarks", "total_synced")
    op.drop_column("sync_watermarks", "last_edat")
    op.drop_column("sync_watermarks", "last_sync_count")
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column(
        "sync_watermarks",
        sa.Column(
            "last_sync_count",
            sa.VARCHAR(length=20),
            server_default=sa.text("'0'::character varying"),
            autoincrement=False,
            nullable=False,
        ),
    )
    op.add_column(
        "sync_watermarks",
        sa.Column(
            "last_edat", sa.VARCHAR(length=10), autoincrement=False, nullable=True
        ),
    )
    op.add_column(
        "sync_watermarks",
        sa.Column(
            "total_synced",
            sa.VARCHAR(length=20),
            server_default=sa.text("'0'::character varying"),
            autoincrement=False,
            nullable=False,
        ),
    )
    op.alter_column(
        "sync_watermarks",
        "updated_at",
        existing_type=sa.DateTime(),
        type_=postgresql.TIMESTAMP(timezone=True),
        existing_nullable=False,
        existing_server_default=sa.text("now()"),
    )
    op.alter_column(
        "sync_watermarks",
        "created_at",
        existing_type=sa.DateTime(),
        type_=postgresql.TIMESTAMP(timezone=True),
        existing_nullable=False,
        existing_server_default=sa.text("now()"),
    )
    op.drop_column("sync_watermarks", "last_sync")
    op.drop_column("sync_watermarks", "source")
    op.drop_column("sync_watermarks", "id")
    op.add_column(
        "corpus_checkpoints",
        sa.Column(
            "sync_watermarks",
            postgresql.JSON(astext_type=sa.Text()),
            autoincrement=False,
            nullable=True,
        ),
    )
    op.alter_column(
        "corpus_checkpoints",
        "updated_at",
        existing_type=sa.DateTime(),
        type_=postgresql.TIMESTAMP(timezone=True),
        existing_nullable=False,
        existing_server_default=sa.text("now()"),
    )
    op.alter_column(
        "corpus_checkpoints",
        "created_at",
        existing_type=sa.DateTime(),
        type_=postgresql.TIMESTAMP(timezone=True),
        existing_nullable=False,
        existing_server_default=sa.text("now()"),
    )
    op.alter_column(
        "corpus_checkpoints",
        "total_vectors",
        existing_type=sa.String(length=50),
        type_=sa.VARCHAR(length=20),
        nullable=False,
        existing_server_default=sa.text("'0'::character varying"),
    )
    op.alter_column(
        "corpus_checkpoints",
        "total_documents",
        existing_type=sa.String(length=50),
        type_=sa.VARCHAR(length=20),
        nullable=False,
        existing_server_default=sa.text("'0'::character varying"),
    )
    op.alter_column(
        "corpus_checkpoints",
        "last_sync_edat",
        existing_type=sa.String(length=50),
        type_=sa.VARCHAR(length=10),
        existing_nullable=True,
    )
    op.alter_column(
        "corpus_checkpoints",
        "document_count",
        existing_type=sa.String(length=50),
        type_=sa.VARCHAR(length=20),
        nullable=False,
        existing_server_default=sa.text("'0'::character varying"),
    )
    op.alter_column(
        "corpus_checkpoints",
        "version",
        existing_type=sa.VARCHAR(length=50),
        nullable=False,
        existing_server_default=sa.text("'1.0'::character varying"),
    )
    op.create_table(
        "pubmed_documents",
        sa.Column("pmid", sa.VARCHAR(length=50), autoincrement=False, nullable=False),
        sa.Column(
            "title", sa.VARCHAR(length=1000), autoincrement=False, nullable=False
        ),
        sa.Column("abstract", sa.TEXT(), autoincrement=False, nullable=True),
        sa.Column(
            "authors",
            postgresql.JSON(astext_type=sa.Text()),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column("publication_date", sa.DATE(), autoincrement=False, nullable=True),
        sa.Column(
            "journal", sa.VARCHAR(length=500), autoincrement=False, nullable=True
        ),
        sa.Column("doi", sa.VARCHAR(length=200), autoincrement=False, nullable=True),
        sa.Column(
            "keywords",
            postgresql.JSON(astext_type=sa.Text()),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "created_at",
            postgresql.TIMESTAMP(timezone=True),
            server_default=sa.text("now()"),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column(
            "updated_at",
            postgresql.TIMESTAMP(timezone=True),
            server_default=sa.text("now()"),
            autoincrement=False,
            nullable=False,
        ),
        sa.PrimaryKeyConstraint("pmid", name=op.f("pubmed_documents_pkey")),
    )
    op.drop_index(
        op.f("ix_documents_universal_source"), table_name="documents_universal"
    )
    op.drop_index(
        op.f("ix_documents_universal_quality_score"), table_name="documents_universal"
    )
    op.drop_index(
        op.f("ix_documents_universal_publication_date"),
        table_name="documents_universal",
    )
    op.drop_index(
        op.f("ix_documents_universal_last_updated"), table_name="documents_universal"
    )
    op.drop_table("documents_universal")
    op.drop_index(op.f("ix_documents_source"), table_name="documents")
    op.drop_index(op.f("ix_documents_published_at"), table_name="documents")
    op.drop_table("documents")
    # ### end Alembic commands ###
